import React, { useState, useEffect, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { Mic, MicOff, Music, User, Bot } from 'lucide-react';
import { toast } from 'sonner';

export default function VoiceTranscription({ onTranscription }) {
  const [isListening, setIsListening] = useState(false);
  const [recognition, setRecognition] = useState(null);
  const [currentSpeaker, setCurrentSpeaker] = useState('unknown');

  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognitionInstance = new SpeechRecognition();
      
      recognitionInstance.continuous = true;
      recognitionInstance.interimResults = true;
      recognitionInstance.lang = 'fr-FR';

      recognitionInstance.onresult = (event) => {
        const last = event.results.length - 1;
        const text = event.results[last][0].transcript;
        const confidence = event.results[last][0].confidence;
        const isFinal = event.results[last].isFinal;

        if (isFinal) {
          // DÃ©tection mathÃ©matique du locuteur via pattern vocal
          const voiceSignature = analyzeVoicePattern(text, confidence);
          
          onTranscription({
            text,
            confidence,
            speaker_id: voiceSignature.speaker_id,
            speaker_type: 'human',
            voice_signature: voiceSignature,
            is_song: detectMusic(text),
            timestamp: new Date().toISOString()
          });
        }
      };

      recognitionInstance.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        toast.error('Erreur reconnaissance vocale');
      };

      setRecognition(recognitionInstance);
    } else {
      toast.error('Reconnaissance vocale non supportÃ©e');
    }

    // Auto-start au chargement (Windows 10/11)
    setTimeout(() => startListening(), 1000);

    return () => {
      if (recognition) {
        recognition.stop();
      }
    };
  }, []);

  const analyzeVoicePattern = (text, confidence) => {
    // Formule mathÃ©matique pour identifier le locuteur
    const textHash = text.split('').reduce((acc, char) => acc + char.charCodeAt(0), 0);
    const speakerScore = (textHash * confidence) % 1000;
    
    return {
      speaker_id: `speaker_${Math.floor(speakerScore)}`,
      pattern_hash: textHash,
      confidence_score: confidence,
      timestamp: Date.now()
    };
  };

  const detectMusic = (text) => {
    // DÃ©tection simple de chanson (mots clÃ©s musicaux)
    const musicKeywords = ['la la', 'na na', 'oh oh', 'yeah', 'lalala'];
    return musicKeywords.some(kw => text.toLowerCase().includes(kw));
  };

  const startListening = () => {
    if (recognition) {
      recognition.start();
      setIsListening(true);
      toast.success('ğŸ¤ Ã‰coute activÃ©e');
    }
  };

  const stopListening = () => {
    if (recognition) {
      recognition.stop();
      setIsListening(false);
      toast.info('ğŸ¤ Ã‰coute dÃ©sactivÃ©e');
    }
  };

  return (
    <div className="flex items-center gap-2">
      <Button
        size="sm"
        variant={isListening ? 'default' : 'outline'}
        onClick={isListening ? stopListening : startListening}
        className={isListening ? 'bg-red-600 hover:bg-red-700 animate-pulse' : ''}
      >
        {isListening ? <MicOff className="w-4 h-4 mr-1" /> : <Mic className="w-4 h-4 mr-1" />}
        {isListening ? 'ArrÃªter' : 'Ã‰couter'}
      </Button>
      
      {isListening && (
        <div className="flex items-center gap-1 text-xs text-slate-600">
          <div className="w-2 h-2 bg-red-600 rounded-full animate-pulse" />
          Enregistrement actif
        </div>
      )}
    </div>
  );
}